{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Bike Sharing Demand with AutoGluon Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: Predict Bike Sharing Demand with AutoGluon\n",
    "This notebook is a template with each step that you need to complete for the project.\n",
    "\n",
    "Please fill in your code where there are explicit `?` markers in the notebook. You are welcome to add more cells and code as you see fit.\n",
    "\n",
    "Once you have completed all the code implementations, please export your notebook as a HTML file so the reviews can view your code. Make sure you have all outputs correctly outputted.\n",
    "\n",
    "`File-> Export Notebook As... -> Export Notebook as HTML`\n",
    "\n",
    "There is a writeup to complete as well after all code implememtation is done. Please answer all questions and attach the necessary tables and charts. You can complete the writeup in either markdown or PDF.\n",
    "\n",
    "Completing the code template and writeup template will cover all of the rubric points for this project.\n",
    "\n",
    "The rubric contains \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. The stand out suggestions are optional. If you decide to pursue the \"stand out suggestions\", you can include the code in this notebook and also discuss the results in the writeup file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create an account with Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Kaggle Account and download API key\n",
    "Below is example of steps to get the API username and key. Each student will have their own username and key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Download the Kaggle dataset using the kaggle python library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up Sagemaker Studio and use starter template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Notebook should be using a `ml.t3.medium` instance (2 vCPU + 4 GiB)\n",
    "2. Notebook should be using kernal: `Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pip\n",
    "# !pip install -U setuptools wheel\n",
    "# !pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "# !pip install autogluon --no-cache-dir\n",
    "# # Without --no-cache-dir, smaller aws instances may have trouble installing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Kaggle API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # create the .kaggle directory and an empty kaggle.json file\n",
    "# !mkdir /home/.kaggle\n",
    "# !touch /home/.kaggle/kaggle.json\n",
    "# !chmod 600 /home/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill in your user name and key from creating the kaggle account and API token file\n",
    "# import json\n",
    "# kaggle_username = \"markawuku\"\n",
    "# kaggle_key = \"56c7b691f3fdb5cf000b08b0c55fde75\"\n",
    "\n",
    "# # Save API token the kaggle.json file\n",
    "# with open(\"/root/.kaggle/kaggle.json\", \"w\") as f:\n",
    "#     f.write(json.dumps({\"username\": kaggle_username, \"key\": kaggle_key}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset, it will be in a .zip file so you'll need to unzip it as well.\n",
    "# !kaggle competitions download -c bike-sharing-demand\n",
    "\n",
    "# If you already downloaded it you can use the -o command to overwrite the file\n",
    "# !unzip -o bike-sharing-demand.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import autogluon.core as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
       "0 2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
       "1 2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
       "2 2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
       "3 2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
       "4 2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
       "\n",
       "   humidity  windspeed  casual  registered  count  \n",
       "0        81        0.0       3          13     16  \n",
       "1        80        0.0       8          32     40  \n",
       "2        80        0.0       5          27     32  \n",
       "3        75        0.0       3          10     13  \n",
       "4        75        0.0       0           1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the train dataset in pandas by reading the csv\n",
    "# Set the parsing of the datetime column so you can use some of the `dt` features in pandas later\n",
    "train = pd.read_csv('data/train.csv', parse_dates=['datetime'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.00000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "      <td>10886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.506614</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.680875</td>\n",
       "      <td>1.418427</td>\n",
       "      <td>20.23086</td>\n",
       "      <td>23.655084</td>\n",
       "      <td>61.886460</td>\n",
       "      <td>12.799395</td>\n",
       "      <td>36.021955</td>\n",
       "      <td>155.552177</td>\n",
       "      <td>191.574132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.116174</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>0.466159</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>7.79159</td>\n",
       "      <td>8.474601</td>\n",
       "      <td>19.245033</td>\n",
       "      <td>8.164537</td>\n",
       "      <td>49.960477</td>\n",
       "      <td>151.039033</td>\n",
       "      <td>181.144454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.94000</td>\n",
       "      <td>16.665000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>7.001500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.50000</td>\n",
       "      <td>24.240000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>12.998000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.24000</td>\n",
       "      <td>31.060000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>16.997900</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>284.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>41.00000</td>\n",
       "      <td>45.455000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>56.996900</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>886.000000</td>\n",
       "      <td>977.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             season       holiday    workingday       weather         temp  \\\n",
       "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
       "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
       "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
       "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
       "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
       "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
       "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
       "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
       "\n",
       "              atemp      humidity     windspeed        casual    registered  \\\n",
       "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
       "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
       "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
       "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
       "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
       "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
       "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
       "\n",
       "              count  \n",
       "count  10886.000000  \n",
       "mean     191.574132  \n",
       "std      181.144454  \n",
       "min        1.000000  \n",
       "25%       42.000000  \n",
       "50%      145.000000  \n",
       "75%      284.000000  \n",
       "max      977.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple output of the train dataset to view some of the min/max/varition of the dataset features.\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>11.365</td>\n",
       "      <td>56</td>\n",
       "      <td>26.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>13.635</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.66</td>\n",
       "      <td>12.880</td>\n",
       "      <td>56</td>\n",
       "      <td>11.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  season  holiday  workingday  weather   temp   atemp  \\\n",
       "0 2011-01-20 00:00:00       1        0           1        1  10.66  11.365   \n",
       "1 2011-01-20 01:00:00       1        0           1        1  10.66  13.635   \n",
       "2 2011-01-20 02:00:00       1        0           1        1  10.66  13.635   \n",
       "3 2011-01-20 03:00:00       1        0           1        1  10.66  12.880   \n",
       "4 2011-01-20 04:00:00       1        0           1        1  10.66  12.880   \n",
       "\n",
       "   humidity  windspeed  \n",
       "0        56    26.0027  \n",
       "1        56     0.0000  \n",
       "2        56     0.0000  \n",
       "3        56    11.0014  \n",
       "4        56    11.0014  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the test pandas dataframe in pandas by reading the csv, remember to parse the datetime!\n",
    "test = pd.read_csv('data/test.csv', parse_dates=['datetime'])\n",
    "test.head()\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-20 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-20 01:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-20 02:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-20 03:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-20 04:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  count\n",
       "0 2011-01-20 00:00:00      0\n",
       "1 2011-01-20 01:00:00      0\n",
       "2 2011-01-20 02:00:00      0\n",
       "3 2011-01-20 03:00:00      0\n",
       "4 2011-01-20 04:00:00      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same thing as train and test dataset\n",
    "submission = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "submission.head()\n",
    "# submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train a model using AutoGluon’s Tabular Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "* We are prediting `count`, so it is the label we are setting.\n",
    "* Ignore `casual` and `registered` columns as they are also not present in the test dataset. \n",
    "* Use the `root_mean_squared_error` as the metric to use for evaluation.\n",
    "* Set a time limit of 10 minutes (600 seconds).\n",
    "* Use the preset `best_quality` to focus on creating the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10886 entries, 0 to 10885\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   datetime    10886 non-null  datetime64[ns]\n",
      " 1   season      10886 non-null  int64         \n",
      " 2   holiday     10886 non-null  int64         \n",
      " 3   workingday  10886 non-null  int64         \n",
      " 4   weather     10886 non-null  int64         \n",
      " 5   temp        10886 non-null  float64       \n",
      " 6   atemp       10886 non-null  float64       \n",
      " 7   humidity    10886 non-null  int64         \n",
      " 8   windspeed   10886 non-null  float64       \n",
      " 9   casual      10886 non-null  int64         \n",
      " 10  registered  10886 non-null  int64         \n",
      " 11  count       10886 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(8)\n",
      "memory usage: 1020.7 KB\n"
     ]
    }
   ],
   "source": [
    "# casual and registered columns to remmove/ignored\n",
    "ignore_cols = ['casual','registered']\n",
    "# train.drop(ignore_cols, axis=1, inplace=True)  # using the learner_kwards={'ignored_columns': ignore_cols} of TabularPredictor \n",
    "\n",
    "target = 'count'\n",
    "metric = 'root_mean_squared_error'\n",
    "ttime = 10 * 60 # train various models for 10 minutes, 10 x 60 seconds\n",
    "train.info() # confirm if casual and registered columns are remmoved - manual drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20221216_163054/\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 600s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20221216_163054/\"\n",
      "AutoGluon Version:  0.6.0\n",
      "Python Version:     3.8.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #62-Ubuntu SMP Tue Nov 22 19:54:14 UTC 2022\n",
      "Train Data Rows:    10886\n",
      "Train Data Columns: 11\n",
      "Label Column: count\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (977, 1, 191.57413, 181.14445)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Dropping user-specified ignored columns: ['casual', 'registered']\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7862.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.78 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', []) : 1 | ['datetime']\n",
      "\t\t('float', [])    : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])      : 5 | ['season', 'holiday', 'workingday', 'weather', 'humidity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "\t\t('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
      "\t\t('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "\t0.4s = Fit runtime\n",
      "\t9 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 399.61s of the 599.57s of remaining time.\n",
      "\t-101.5462\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 396.92s of the 596.88s of remaining time.\n",
      "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 396.78s of the 596.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-131.4609\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.91s\t = Training   runtime\n",
      "\t15.39s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 334.47s of the 534.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-131.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.11s\t = Training   runtime\n",
      "\t2.7s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 313.73s of the 513.69s of remaining time.\n",
      "\t-116.5484\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.29s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 302.3s of the 502.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-130.4619\t = Validation score   (-root_mean_squared_error)\n",
      "\t160.72s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 136.24s of the 336.2s of remaining time.\n",
      "\t-124.6007\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.96s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 132.39s of the 332.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-135.8325\t = Validation score   (-root_mean_squared_error)\n",
      "\t52.94s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 75.39s of the 275.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-131.6247\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.68s\t = Training   runtime\n",
      "\t0.73s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 59.15s of the 259.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-142.3361\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.16s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 0.42s of the 200.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-167.8689\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.9s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 188.74s of remaining time.\n",
      "\t-84.1251\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 188.27s of the 188.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-60.4946\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.0s\t = Training   runtime\n",
      "\t7.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 153.5s of the 153.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-55.1627\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.21s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 137.88s of the 137.87s of remaining time.\n",
      "\t-53.327\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.42s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 119.56s of the 119.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-55.5655\t = Validation score   (-root_mean_squared_error)\n",
      "\t46.21s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 69.28s of the 69.26s of remaining time.\n",
      "\t-54.296\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.25s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 63.13s of the 63.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-51.4467\t = Validation score   (-root_mean_squared_error)\n",
      "\t55.82s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 3.26s of the 3.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-54.9857\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.63s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -9.3s of remaining time.\n",
      "\t-50.3973\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 609.92s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20221216_163054/\")\n"
     ]
    }
   ],
   "source": [
    "# to ignore columns of train data in fit, use learnier_kwargs 'ignored_columns' of TabularPredictor\n",
    "predictor = TabularPredictor(label=target, eval_metric=metric, learner_kwargs={'ignored_columns': ignore_cols}).fit(\n",
    "    train_data=train,\n",
    "    time_limit=ttime,\n",
    "    presets='best_quality'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review AutoGluon's training run with ranking of models that did the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                     model   score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3  -50.397299      22.317726  442.836139                0.000764           0.591672            3       True         20\n",
      "1   NeuralNetFastAI_BAG_L2  -51.446703      21.325593  419.577812                0.611587          55.819029            2       True         18\n",
      "2   RandomForestMSE_BAG_L2  -53.327027      21.214292  381.178461                0.500286          17.419677            2       True         15\n",
      "3     ExtraTreesMSE_BAG_L2  -54.295980      21.205088  369.005760                0.491083           5.246977            2       True         17\n",
      "4           XGBoost_BAG_L2  -54.985735      20.875395  371.384517                0.161389           7.625733            2       True         19\n",
      "5          LightGBM_BAG_L2  -55.162694      21.001076  374.963897                0.287070          11.205114            2       True         14\n",
      "6          CatBoost_BAG_L2  -55.565513      20.815950  409.964488                0.101945          46.205705            2       True         16\n",
      "7        LightGBMXT_BAG_L2  -60.494604      28.054396  392.756623                7.340391          28.997839            2       True         13\n",
      "8    KNeighborsDist_BAG_L1  -84.125061       0.052007    0.057873                0.052007           0.057873            1       True          2\n",
      "9      WeightedEnsemble_L2  -84.125061       0.053028    0.512507                0.001021           0.454634            2       True         12\n",
      "10   KNeighborsUnif_BAG_L1 -101.546199       0.031702    0.042162                0.031702           0.042162            1       True          1\n",
      "11  RandomForestMSE_BAG_L1 -116.548359       0.535277   10.285983                0.535277          10.285983            1       True          5\n",
      "12    ExtraTreesMSE_BAG_L1 -124.600676       0.398963    2.964968                0.398963           2.964968            1       True          7\n",
      "13         CatBoost_BAG_L1 -130.461928       0.137559  160.719891                0.137559         160.719891            1       True          6\n",
      "14         LightGBM_BAG_L1 -131.054162       2.697017   15.106461                2.697017          15.106461            1       True          4\n",
      "15       LightGBMXT_BAG_L1 -131.460909      15.387416   48.905933               15.387416          48.905933            1       True          3\n",
      "16          XGBoost_BAG_L1 -131.624665       0.732848   11.678730                0.732848          11.678730            1       True          9\n",
      "17  NeuralNetFastAI_BAG_L1 -135.832490       0.407754   52.940744                0.407754          52.940744            1       True          8\n",
      "18   NeuralNetTorch_BAG_L1 -142.336070       0.309500   54.160956                0.309500          54.160956            1       True         10\n",
      "19    LightGBMLarge_BAG_L1 -167.868914       0.023963    6.895083                0.023963           6.895083            1       True         11\n",
      "Number of models trained: 20\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XT', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_KNN', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])                : 3 | ['temp', 'atemp', 'windspeed']\n",
      "('int', [])                  : 3 | ['season', 'weather', 'humidity']\n",
      "('int', ['bool'])            : 2 | ['holiday', 'workingday']\n",
      "('int', ['datetime_as_int']) : 5 | ['datetime', 'datetime.year', 'datetime.month', 'datetime.day', 'datetime.dayofweek']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/mlspace/lib/python3.8/site-packages/autogluon/core/utils/plots.py:138: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_types': {'KNeighborsUnif_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'KNeighborsDist_BAG_L1': 'StackerEnsembleModel_KNN',\n",
       "  'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L1': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L1': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L1': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L1': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L1': 'StackerEnsembleModel_XGBoost',\n",
       "  'NeuralNetTorch_BAG_L1': 'StackerEnsembleModel_TabularNeuralNetTorch',\n",
       "  'LightGBMLarge_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'RandomForestMSE_BAG_L2': 'StackerEnsembleModel_RF',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'ExtraTreesMSE_BAG_L2': 'StackerEnsembleModel_XT',\n",
       "  'NeuralNetFastAI_BAG_L2': 'StackerEnsembleModel_NNFastAiTabular',\n",
       "  'XGBoost_BAG_L2': 'StackerEnsembleModel_XGBoost',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'KNeighborsUnif_BAG_L1': -101.54619908446061,\n",
       "  'KNeighborsDist_BAG_L1': -84.12506123181602,\n",
       "  'LightGBMXT_BAG_L1': -131.46090891834504,\n",
       "  'LightGBM_BAG_L1': -131.054161598899,\n",
       "  'RandomForestMSE_BAG_L1': -116.54835939455667,\n",
       "  'CatBoost_BAG_L1': -130.46192810341705,\n",
       "  'ExtraTreesMSE_BAG_L1': -124.60067564699747,\n",
       "  'NeuralNetFastAI_BAG_L1': -135.83248985116188,\n",
       "  'XGBoost_BAG_L1': -131.62466543942023,\n",
       "  'NeuralNetTorch_BAG_L1': -142.3360701570755,\n",
       "  'LightGBMLarge_BAG_L1': -167.86891405622157,\n",
       "  'WeightedEnsemble_L2': -84.12506123181602,\n",
       "  'LightGBMXT_BAG_L2': -60.494603839542705,\n",
       "  'LightGBM_BAG_L2': -55.16269359746266,\n",
       "  'RandomForestMSE_BAG_L2': -53.327027046081305,\n",
       "  'CatBoost_BAG_L2': -55.56551330489616,\n",
       "  'ExtraTreesMSE_BAG_L2': -54.29598048878241,\n",
       "  'NeuralNetFastAI_BAG_L2': -51.44670282201102,\n",
       "  'XGBoost_BAG_L2': -54.985735036581104,\n",
       "  'WeightedEnsemble_L3': -50.397298939074005},\n",
       " 'model_best': 'WeightedEnsemble_L3',\n",
       " 'model_paths': {'KNeighborsUnif_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/KNeighborsUnif_BAG_L1/',\n",
       "  'KNeighborsDist_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/KNeighborsDist_BAG_L1/',\n",
       "  'LightGBMXT_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/LightGBMXT_BAG_L1/',\n",
       "  'LightGBM_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/LightGBM_BAG_L1/',\n",
       "  'RandomForestMSE_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/RandomForestMSE_BAG_L1/',\n",
       "  'CatBoost_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/CatBoost_BAG_L1/',\n",
       "  'ExtraTreesMSE_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/ExtraTreesMSE_BAG_L1/',\n",
       "  'NeuralNetFastAI_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/NeuralNetFastAI_BAG_L1/',\n",
       "  'XGBoost_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/XGBoost_BAG_L1/',\n",
       "  'NeuralNetTorch_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/NeuralNetTorch_BAG_L1/',\n",
       "  'LightGBMLarge_BAG_L1': 'AutogluonModels/ag-20221216_163054/models/LightGBMLarge_BAG_L1/',\n",
       "  'WeightedEnsemble_L2': 'AutogluonModels/ag-20221216_163054/models/WeightedEnsemble_L2/',\n",
       "  'LightGBMXT_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/LightGBMXT_BAG_L2/',\n",
       "  'LightGBM_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/LightGBM_BAG_L2/',\n",
       "  'RandomForestMSE_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/RandomForestMSE_BAG_L2/',\n",
       "  'CatBoost_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/CatBoost_BAG_L2/',\n",
       "  'ExtraTreesMSE_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/ExtraTreesMSE_BAG_L2/',\n",
       "  'NeuralNetFastAI_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/NeuralNetFastAI_BAG_L2/',\n",
       "  'XGBoost_BAG_L2': 'AutogluonModels/ag-20221216_163054/models/XGBoost_BAG_L2/',\n",
       "  'WeightedEnsemble_L3': 'AutogluonModels/ag-20221216_163054/models/WeightedEnsemble_L3/'},\n",
       " 'model_fit_times': {'KNeighborsUnif_BAG_L1': 0.04216194152832031,\n",
       "  'KNeighborsDist_BAG_L1': 0.05787324905395508,\n",
       "  'LightGBMXT_BAG_L1': 48.905933141708374,\n",
       "  'LightGBM_BAG_L1': 15.106460809707642,\n",
       "  'RandomForestMSE_BAG_L1': 10.285983324050903,\n",
       "  'CatBoost_BAG_L1': 160.71989059448242,\n",
       "  'ExtraTreesMSE_BAG_L1': 2.96496844291687,\n",
       "  'NeuralNetFastAI_BAG_L1': 52.94074368476868,\n",
       "  'XGBoost_BAG_L1': 11.678729772567749,\n",
       "  'NeuralNetTorch_BAG_L1': 54.16095566749573,\n",
       "  'LightGBMLarge_BAG_L1': 6.895082712173462,\n",
       "  'WeightedEnsemble_L2': 0.4546339511871338,\n",
       "  'LightGBMXT_BAG_L2': 28.997839212417603,\n",
       "  'LightGBM_BAG_L2': 11.205113649368286,\n",
       "  'RandomForestMSE_BAG_L2': 17.41967749595642,\n",
       "  'CatBoost_BAG_L2': 46.20570492744446,\n",
       "  'ExtraTreesMSE_BAG_L2': 5.246977090835571,\n",
       "  'NeuralNetFastAI_BAG_L2': 55.819029092788696,\n",
       "  'XGBoost_BAG_L2': 7.625733375549316,\n",
       "  'WeightedEnsemble_L3': 0.5916717052459717},\n",
       " 'model_pred_times': {'KNeighborsUnif_BAG_L1': 0.03170156478881836,\n",
       "  'KNeighborsDist_BAG_L1': 0.05200695991516113,\n",
       "  'LightGBMXT_BAG_L1': 15.387415647506714,\n",
       "  'LightGBM_BAG_L1': 2.6970174312591553,\n",
       "  'RandomForestMSE_BAG_L1': 0.5352768898010254,\n",
       "  'CatBoost_BAG_L1': 0.1375594139099121,\n",
       "  'ExtraTreesMSE_BAG_L1': 0.39896321296691895,\n",
       "  'NeuralNetFastAI_BAG_L1': 0.40775370597839355,\n",
       "  'XGBoost_BAG_L1': 0.7328476905822754,\n",
       "  'NeuralNetTorch_BAG_L1': 0.30949974060058594,\n",
       "  'LightGBMLarge_BAG_L1': 0.023963212966918945,\n",
       "  'WeightedEnsemble_L2': 0.0010213851928710938,\n",
       "  'LightGBMXT_BAG_L2': 7.340390920639038,\n",
       "  'LightGBM_BAG_L2': 0.28707027435302734,\n",
       "  'RandomForestMSE_BAG_L2': 0.5002861022949219,\n",
       "  'CatBoost_BAG_L2': 0.1019446849822998,\n",
       "  'ExtraTreesMSE_BAG_L2': 0.49108266830444336,\n",
       "  'NeuralNetFastAI_BAG_L2': 0.6115872859954834,\n",
       "  'XGBoost_BAG_L2': 0.16138911247253418,\n",
       "  'WeightedEnsemble_L3': 0.0007641315460205078},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'model_hyperparams': {'KNeighborsUnif_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'KNeighborsDist_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'NeuralNetTorch_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMLarge_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'RandomForestMSE_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'ExtraTreesMSE_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True,\n",
       "   'use_child_oof': True},\n",
       "  'NeuralNetFastAI_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'XGBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                      model   score_val  pred_time_val    fit_time  \\\n",
       " 0      WeightedEnsemble_L3  -50.397299      22.317726  442.836139   \n",
       " 1   NeuralNetFastAI_BAG_L2  -51.446703      21.325593  419.577812   \n",
       " 2   RandomForestMSE_BAG_L2  -53.327027      21.214292  381.178461   \n",
       " 3     ExtraTreesMSE_BAG_L2  -54.295980      21.205088  369.005760   \n",
       " 4           XGBoost_BAG_L2  -54.985735      20.875395  371.384517   \n",
       " 5          LightGBM_BAG_L2  -55.162694      21.001076  374.963897   \n",
       " 6          CatBoost_BAG_L2  -55.565513      20.815950  409.964488   \n",
       " 7        LightGBMXT_BAG_L2  -60.494604      28.054396  392.756623   \n",
       " 8    KNeighborsDist_BAG_L1  -84.125061       0.052007    0.057873   \n",
       " 9      WeightedEnsemble_L2  -84.125061       0.053028    0.512507   \n",
       " 10   KNeighborsUnif_BAG_L1 -101.546199       0.031702    0.042162   \n",
       " 11  RandomForestMSE_BAG_L1 -116.548359       0.535277   10.285983   \n",
       " 12    ExtraTreesMSE_BAG_L1 -124.600676       0.398963    2.964968   \n",
       " 13         CatBoost_BAG_L1 -130.461928       0.137559  160.719891   \n",
       " 14         LightGBM_BAG_L1 -131.054162       2.697017   15.106461   \n",
       " 15       LightGBMXT_BAG_L1 -131.460909      15.387416   48.905933   \n",
       " 16          XGBoost_BAG_L1 -131.624665       0.732848   11.678730   \n",
       " 17  NeuralNetFastAI_BAG_L1 -135.832490       0.407754   52.940744   \n",
       " 18   NeuralNetTorch_BAG_L1 -142.336070       0.309500   54.160956   \n",
       " 19    LightGBMLarge_BAG_L1 -167.868914       0.023963    6.895083   \n",
       " \n",
       "     pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0                 0.000764           0.591672            3       True   \n",
       " 1                 0.611587          55.819029            2       True   \n",
       " 2                 0.500286          17.419677            2       True   \n",
       " 3                 0.491083           5.246977            2       True   \n",
       " 4                 0.161389           7.625733            2       True   \n",
       " 5                 0.287070          11.205114            2       True   \n",
       " 6                 0.101945          46.205705            2       True   \n",
       " 7                 7.340391          28.997839            2       True   \n",
       " 8                 0.052007           0.057873            1       True   \n",
       " 9                 0.001021           0.454634            2       True   \n",
       " 10                0.031702           0.042162            1       True   \n",
       " 11                0.535277          10.285983            1       True   \n",
       " 12                0.398963           2.964968            1       True   \n",
       " 13                0.137559         160.719891            1       True   \n",
       " 14                2.697017          15.106461            1       True   \n",
       " 15               15.387416          48.905933            1       True   \n",
       " 16                0.732848          11.678730            1       True   \n",
       " 17                0.407754          52.940744            1       True   \n",
       " 18                0.309500          54.160956            1       True   \n",
       " 19                0.023963           6.895083            1       True   \n",
       " \n",
       "     fit_order  \n",
       " 0          20  \n",
       " 1          18  \n",
       " 2          15  \n",
       " 3          17  \n",
       " 4          19  \n",
       " 5          14  \n",
       " 6          16  \n",
       " 7          13  \n",
       " 8           2  \n",
       " 9          12  \n",
       " 10          1  \n",
       " 11          5  \n",
       " 12          7  \n",
       " 13          6  \n",
       " 14          4  \n",
       " 15          3  \n",
       " 16          9  \n",
       " 17          8  \n",
       " 18         10  \n",
       " 19         11  }"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-84.125061</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>0.057873</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>0.057873</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-84.125061</td>\n",
       "      <td>0.038656</td>\n",
       "      <td>0.053028</td>\n",
       "      <td>0.512507</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.001021</td>\n",
       "      <td>0.454634</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestMSE_BAG_L1</td>\n",
       "      <td>-42.939157</td>\n",
       "      <td>-116.548359</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.535277</td>\n",
       "      <td>10.285983</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.535277</td>\n",
       "      <td>10.285983</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesMSE_BAG_L1</td>\n",
       "      <td>-45.921107</td>\n",
       "      <td>-124.600676</td>\n",
       "      <td>0.559784</td>\n",
       "      <td>0.398963</td>\n",
       "      <td>2.964968</td>\n",
       "      <td>0.559784</td>\n",
       "      <td>0.398963</td>\n",
       "      <td>2.964968</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesMSE_BAG_L2</td>\n",
       "      <td>-62.756012</td>\n",
       "      <td>-54.295980</td>\n",
       "      <td>45.278469</td>\n",
       "      <td>21.205088</td>\n",
       "      <td>369.005760</td>\n",
       "      <td>0.636455</td>\n",
       "      <td>0.491083</td>\n",
       "      <td>5.246977</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>-70.693174</td>\n",
       "      <td>-101.546199</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.042162</td>\n",
       "      <td>0.038055</td>\n",
       "      <td>0.031702</td>\n",
       "      <td>0.042162</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestMSE_BAG_L2</td>\n",
       "      <td>-73.960021</td>\n",
       "      <td>-53.327027</td>\n",
       "      <td>45.345780</td>\n",
       "      <td>21.214292</td>\n",
       "      <td>381.178461</td>\n",
       "      <td>0.703765</td>\n",
       "      <td>0.500286</td>\n",
       "      <td>17.419677</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>-77.701485</td>\n",
       "      <td>-54.985735</td>\n",
       "      <td>44.961787</td>\n",
       "      <td>20.875395</td>\n",
       "      <td>371.384517</td>\n",
       "      <td>0.319773</td>\n",
       "      <td>0.161389</td>\n",
       "      <td>7.625733</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>-84.631163</td>\n",
       "      <td>-55.162694</td>\n",
       "      <td>45.287336</td>\n",
       "      <td>21.001076</td>\n",
       "      <td>374.963897</td>\n",
       "      <td>0.645321</td>\n",
       "      <td>0.287070</td>\n",
       "      <td>11.205114</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>-85.623725</td>\n",
       "      <td>-131.624665</td>\n",
       "      <td>1.386324</td>\n",
       "      <td>0.732848</td>\n",
       "      <td>11.678730</td>\n",
       "      <td>1.386324</td>\n",
       "      <td>0.732848</td>\n",
       "      <td>11.678730</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>-88.031893</td>\n",
       "      <td>-130.461928</td>\n",
       "      <td>0.260110</td>\n",
       "      <td>0.137559</td>\n",
       "      <td>160.719891</td>\n",
       "      <td>0.260110</td>\n",
       "      <td>0.137559</td>\n",
       "      <td>160.719891</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>-90.570763</td>\n",
       "      <td>-131.054162</td>\n",
       "      <td>4.226907</td>\n",
       "      <td>2.697017</td>\n",
       "      <td>15.106461</td>\n",
       "      <td>4.226907</td>\n",
       "      <td>2.697017</td>\n",
       "      <td>15.106461</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>-95.585799</td>\n",
       "      <td>-60.494604</td>\n",
       "      <td>58.692147</td>\n",
       "      <td>28.054396</td>\n",
       "      <td>392.756623</td>\n",
       "      <td>14.050133</td>\n",
       "      <td>7.340391</td>\n",
       "      <td>28.997839</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>-97.172702</td>\n",
       "      <td>-131.460909</td>\n",
       "      <td>35.373201</td>\n",
       "      <td>15.387416</td>\n",
       "      <td>48.905933</td>\n",
       "      <td>35.373201</td>\n",
       "      <td>15.387416</td>\n",
       "      <td>48.905933</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>-110.881689</td>\n",
       "      <td>-55.565513</td>\n",
       "      <td>44.745511</td>\n",
       "      <td>20.815950</td>\n",
       "      <td>409.964488</td>\n",
       "      <td>0.103496</td>\n",
       "      <td>0.101945</td>\n",
       "      <td>46.205705</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>-126.603033</td>\n",
       "      <td>-135.832490</td>\n",
       "      <td>1.197317</td>\n",
       "      <td>0.407754</td>\n",
       "      <td>52.940744</td>\n",
       "      <td>1.197317</td>\n",
       "      <td>0.407754</td>\n",
       "      <td>52.940744</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>-139.091813</td>\n",
       "      <td>-142.336070</td>\n",
       "      <td>0.898425</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>54.160956</td>\n",
       "      <td>0.898425</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>54.160956</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>-141.852892</td>\n",
       "      <td>-50.397299</td>\n",
       "      <td>47.272316</td>\n",
       "      <td>22.317726</td>\n",
       "      <td>442.836139</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.591672</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>-164.421382</td>\n",
       "      <td>-167.868914</td>\n",
       "      <td>0.084764</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>6.895083</td>\n",
       "      <td>0.084764</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>6.895083</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>-200.902863</td>\n",
       "      <td>-51.446703</td>\n",
       "      <td>45.929156</td>\n",
       "      <td>21.325593</td>\n",
       "      <td>419.577812</td>\n",
       "      <td>1.287141</td>\n",
       "      <td>0.611587</td>\n",
       "      <td>55.819029</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test   score_val  pred_time_test  \\\n",
       "0    KNeighborsDist_BAG_L1   -0.000000  -84.125061        0.036026   \n",
       "1      WeightedEnsemble_L2   -0.000000  -84.125061        0.038656   \n",
       "2   RandomForestMSE_BAG_L1  -42.939157 -116.548359        0.581102   \n",
       "3     ExtraTreesMSE_BAG_L1  -45.921107 -124.600676        0.559784   \n",
       "4     ExtraTreesMSE_BAG_L2  -62.756012  -54.295980       45.278469   \n",
       "5    KNeighborsUnif_BAG_L1  -70.693174 -101.546199        0.038055   \n",
       "6   RandomForestMSE_BAG_L2  -73.960021  -53.327027       45.345780   \n",
       "7           XGBoost_BAG_L2  -77.701485  -54.985735       44.961787   \n",
       "8          LightGBM_BAG_L2  -84.631163  -55.162694       45.287336   \n",
       "9           XGBoost_BAG_L1  -85.623725 -131.624665        1.386324   \n",
       "10         CatBoost_BAG_L1  -88.031893 -130.461928        0.260110   \n",
       "11         LightGBM_BAG_L1  -90.570763 -131.054162        4.226907   \n",
       "12       LightGBMXT_BAG_L2  -95.585799  -60.494604       58.692147   \n",
       "13       LightGBMXT_BAG_L1  -97.172702 -131.460909       35.373201   \n",
       "14         CatBoost_BAG_L2 -110.881689  -55.565513       44.745511   \n",
       "15  NeuralNetFastAI_BAG_L1 -126.603033 -135.832490        1.197317   \n",
       "16   NeuralNetTorch_BAG_L1 -139.091813 -142.336070        0.898425   \n",
       "17     WeightedEnsemble_L3 -141.852892  -50.397299       47.272316   \n",
       "18    LightGBMLarge_BAG_L1 -164.421382 -167.868914        0.084764   \n",
       "19  NeuralNetFastAI_BAG_L2 -200.902863  -51.446703       45.929156   \n",
       "\n",
       "    pred_time_val    fit_time  pred_time_test_marginal  \\\n",
       "0        0.052007    0.057873                 0.036026   \n",
       "1        0.053028    0.512507                 0.002630   \n",
       "2        0.535277   10.285983                 0.581102   \n",
       "3        0.398963    2.964968                 0.559784   \n",
       "4       21.205088  369.005760                 0.636455   \n",
       "5        0.031702    0.042162                 0.038055   \n",
       "6       21.214292  381.178461                 0.703765   \n",
       "7       20.875395  371.384517                 0.319773   \n",
       "8       21.001076  374.963897                 0.645321   \n",
       "9        0.732848   11.678730                 1.386324   \n",
       "10       0.137559  160.719891                 0.260110   \n",
       "11       2.697017   15.106461                 4.226907   \n",
       "12      28.054396  392.756623                14.050133   \n",
       "13      15.387416   48.905933                35.373201   \n",
       "14      20.815950  409.964488                 0.103496   \n",
       "15       0.407754   52.940744                 1.197317   \n",
       "16       0.309500   54.160956                 0.898425   \n",
       "17      22.317726  442.836139                 0.002940   \n",
       "18       0.023963    6.895083                 0.084764   \n",
       "19      21.325593  419.577812                 1.287141   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.052007           0.057873            1       True   \n",
       "1                 0.001021           0.454634            2       True   \n",
       "2                 0.535277          10.285983            1       True   \n",
       "3                 0.398963           2.964968            1       True   \n",
       "4                 0.491083           5.246977            2       True   \n",
       "5                 0.031702           0.042162            1       True   \n",
       "6                 0.500286          17.419677            2       True   \n",
       "7                 0.161389           7.625733            2       True   \n",
       "8                 0.287070          11.205114            2       True   \n",
       "9                 0.732848          11.678730            1       True   \n",
       "10                0.137559         160.719891            1       True   \n",
       "11                2.697017          15.106461            1       True   \n",
       "12                7.340391          28.997839            2       True   \n",
       "13               15.387416          48.905933            1       True   \n",
       "14                0.101945          46.205705            2       True   \n",
       "15                0.407754          52.940744            1       True   \n",
       "16                0.309500          54.160956            1       True   \n",
       "17                0.000764           0.591672            3       True   \n",
       "18                0.023963           6.895083            1       True   \n",
       "19                0.611587          55.819029            2       True   \n",
       "\n",
       "    fit_order  \n",
       "0           2  \n",
       "1          12  \n",
       "2           5  \n",
       "3           7  \n",
       "4          17  \n",
       "5           1  \n",
       "6          15  \n",
       "7          19  \n",
       "8          14  \n",
       "9           9  \n",
       "10          6  \n",
       "11          4  \n",
       "12         13  \n",
       "13          3  \n",
       "14         16  \n",
       "15          8  \n",
       "16         10  \n",
       "17         20  \n",
       "18         11  \n",
       "19         18  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model by autogluon\n",
    "predictor.leaderboard(data=train, silent=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictor.feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create predictions from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.345877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.131622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.567802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.524109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.965538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6488</th>\n",
       "      <td>157.488251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6489</th>\n",
       "      <td>157.505081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6490</th>\n",
       "      <td>153.458344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>146.478683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>146.030579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6493 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           count\n",
       "0      26.345877\n",
       "1      43.131622\n",
       "2      47.567802\n",
       "3      50.524109\n",
       "4      52.965538\n",
       "...          ...\n",
       "6488  157.488251\n",
       "6489  157.505081\n",
       "6490  153.458344\n",
       "6491  146.478683\n",
       "6492  146.030579\n",
       "\n",
       "[6493 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evalauation = predictor.evaluate(test)\n",
    "predictions = predictor.predict(test)\n",
    "\n",
    "y_pred = pd.DataFrame(predictions, columns=['count'])\n",
    "y_pred # print dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Kaggle will reject the submission if we don't set everything to be > 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6493.000000\n",
       "mean      100.251656\n",
       "std        87.535828\n",
       "min        -1.232798\n",
       "25%        23.113815\n",
       "50%        69.305283\n",
       "75%       165.564026\n",
       "max       353.474365\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the `predictions` series to see if there are any negative values\n",
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative values:  -4.846719\n"
     ]
    }
   ],
   "source": [
    "# How many negative values do we have?\n",
    "# (df[df<0]).sum().sum()\n",
    "neg_values = (predictions[predictions < 0]).sum().sum()\n",
    "print('Number of negative values: ', neg_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set them to zero\n",
    "# df[df < 0] = 0\n",
    "predictions[predictions < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set predictions to submission dataframe, save, and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"count\"] = predictions\n",
    "submission.to_csv(\"LOCAL_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f submission.csv -m \"first raw submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View submission via the command line or in the web browser under the competition's page - `My Submissions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6\n",
    "\n",
    "# !kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial score of `1.77321`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Data Analysis and Creating an additional feature\n",
    "* Any additional feature will do, but a great suggestion would be to separate out the datetime into hour, day, or month parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of all features to show the distribution of each one relative to the data. This is part of the exploritory data analysis\n",
    "train.hist(figsize=(30,18), legend=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "remove_time = train.drop('datetime', axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(35,30))\n",
    "sns.heatmap(remove_time, annot = False, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature\n",
    "train['hour'] = train['datetime'].dt.hour\n",
    "train['day'] = train['datetime'].dt.day\n",
    "train['month'] = train['datetime'].dt.month\n",
    "train['year'] = train['datetime'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "test['hour'] = test['datetime'].dt.hour\n",
    "test['day'] = test['datetime'].dt.day\n",
    "test['month'] = test['datetime'].dt.month\n",
    "test['year'] = test['datetime'].dt.year\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make category types for these so models know they are not just numbers\n",
    "* AutoGluon originally sees these as ints, but in reality they are int representations of a category.\n",
    "* Setting the dtype to category will classify these as categories in AutoGluon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"season\"] = train['season'].astype('category')\n",
    "train[\"weather\"] = train['weather'].astype('category')\n",
    "\n",
    "test[\"season\"] = test['season'].astype('category')\n",
    "test[\"weather\"] = test['weather'].astype('category')\n",
    "\n",
    "                                         \n",
    "train.info()                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View are new feature\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View histogram of all features again now with the hour feature\n",
    "train.hist(figsize=(30,22), legend=True, grid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Rerun the model with the same settings as before, just with more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features = TabularPredictor(label=target, eval_metric = metric).fit(\n",
    "    train_data = train,    \n",
    "    time_limit = ttime,    \n",
    "    presets = 'best_quality'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_new_features.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with new features\n",
    "new_feat_predictions = predictor_new_features.predict(test)\n",
    "new_feat_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same submitting predictions\n",
    "submission_new_features = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "\n",
    "# replace counts with new predictions\n",
    "submission_new_features[\"count\"] = new_feat_predictions\n",
    "submission_new_features.to_csv(\"LOCAL_submission_new_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f LOCAL_submission_new_features.csv -m \"new features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Score of `0.72416`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Hyper parameter optimization\n",
    "* There are many options for hyper parameter optimization.\n",
    "* Options are to change the AutoGluon higher level parameters or the individual model hyperparameters.\n",
    "* The hyperparameters of the models themselves that are in AutoGluon. Those need the `hyperparameter` and `hyperparameter_tune_kwargs` arguments."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6a: AutoGluon high level paramter set to `light`\n",
    "`light`: Results in smaller models. Generally will make inference speed much faster and disk usage much lower, but with worse accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictor_light_hpo = TabularPredictor(label=target, eval_metric = metric).fit(\n",
    "    train_data = train,    \n",
    "    time_limit = ttime,    \n",
    "    presets = 'best_quality',\n",
    "    hyperparameters='light'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_light_hpo.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to set all negative values to zero\n",
    "\n",
    "predictions_light_hpo = predictor_light_hpo.predict(test)\n",
    "predictions_light_hpo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_light_hpo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_val_light_hpo = (predictions_light_hpo[predictions_light_hpo < 0]).sum().sum()\n",
    "print('Number of negative values: ', neg_val_light_hpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same submitting predictions\n",
    "submission_light_hpo = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "\n",
    "submission_light_hpo[\"count\"] = predictions_light_hpo\n",
    "submission_light_hpo.to_csv(\"LOCAL_submission_new_light_hpo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c bike-sharing-demand -f LOCAL_submission_new_light_hpo.csv -m \"new features with 'light' hyperparameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Score of `0.47104`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6b: AutoGluon low level hyperparameter tuning raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init = pd.read_csv('data/train.csv', parse_dates=['datetime'])\n",
    "test_init = pd.read_csv('data/test.csv', parse_dates=['datetime'])\n",
    "submission_init = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "\n",
    "ignore_cols = ['casual','registered']\n",
    "train_init.drop(ignore_cols, axis=1, inplace=True)  # using the ignored_colums kwargs of TabularPredictor \n",
    "\n",
    "target = 'count'\n",
    "metric = 'root_mean_squared_error'\n",
    "ttime = 10 * 60 # train various models for 10 minutes, 10 x 60 seconds\n",
    "train_init.info() # confirm if casual and registered columns are remmoved - manual drop\n",
    "\n",
    "\n",
    "# setting up individual hyper-parameters for each algorithm\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "gbm_options = {\n",
    "    # 'num_boost_round': 500,\n",
    "    'num_leaves': ag.space.Int(lower=100, upper=500, default=250),\n",
    "    # 'tree_learner': 'feature',  #  serial, feature, data, voting\n",
    "}\n",
    "\n",
    "\n",
    "# https://catboost.ai/docs/concepts/parameter-tuning.html\n",
    "cat_options = {\n",
    "    'iterations':  ag.space.Int(200, 500, default=250),\n",
    "    # 'depth': ag.space.Int(4, 10, default=6),\n",
    "    # 'random_strength': ag.space.Int(0, 20, default=7),\n",
    "}\n",
    "\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "xgb_options = { # empyt dict uses default params\n",
    "}\n",
    "\n",
    "\n",
    "nueral_net_option = {\n",
    "    # 'num_epochs': 200,\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-1, default=5e-4, log=True),\n",
    "    'dropout_prob': ag.space.Real(0.01, 0.6, default=0.1),\n",
    "    # 'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparamter for each model\n",
    "# {} uses autogluon default presets\n",
    "hyperparameters = {\n",
    "    'GBM': gbm_options,\n",
    "    'CAT': cat_options,\n",
    "    'NN_TORCH': nueral_net_option,\n",
    "    'XGB': xgb_options,\n",
    "    'RF': {},\n",
    "    'FASTAI': {}\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': 10,\n",
    "    'searcher': 'auto',  # auto random, bayesopt\n",
    "    'scheduler': 'local', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "predictor_init = TabularPredictor(label=target, eval_metric=metric).fit(\n",
    "    train_data = train_init,\n",
    "    time_limit = ttime,\n",
    "    presets = 'best_quality',\n",
    "    hyperparameters = hyperparameters,\n",
    "    hyperparameter_tune_kwargs = hyperparameter_tune_kwargs   \n",
    ")\n",
    "\n",
    "\n",
    "predictor_init.fit_summary()\n",
    "\n",
    "\n",
    "init_predictions = predictor_init.predict(test_init)\n",
    "init_predictions.head()\n",
    "\n",
    "\n",
    "init_predictions[init_predictions < 0] = 0\n",
    "\n",
    "\n",
    "submission_init[\"count\"] = init_predictions\n",
    "submission_init.to_csv(\"init_preds/INIT_submission.csv\", index=False)\n",
    "\n",
    "\n",
    "!kaggle competitions submit -c bike-sharing-demand -f init_preds/INIT_submission.csv -m \"Init raw submission\"\n",
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6c: AutoGluon low level hyperparameter tuning using new features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_feat = pd.read_csv('data/train.csv', parse_dates=['datetime'])\n",
    "test_feat = pd.read_csv('data/test.csv', parse_dates=['datetime'])\n",
    "submission_feat = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "\n",
    "ignore_cols = ['casual','registered']\n",
    "train_feat.drop(ignore_cols, axis=1, inplace=True)  # using the ignored_colums kwargs of TabularPredictor \n",
    "\n",
    "target = 'count'\n",
    "metric = 'root_mean_squared_error'\n",
    "ttime = 10 * 60 # train various models for 10 minutes, 10 x 60 seconds\n",
    "\n",
    "\n",
    "train_feat['hour'] = train_feat['datetime'].dt.hour\n",
    "train_feat['day'] = train_feat['datetime'].dt.day\n",
    "train_feat['month'] = train_feat['datetime'].dt.month\n",
    "train_feat['year'] = train_feat['datetime'].dt.year\n",
    "test_feat['hour'] = test_feat['datetime'].dt.hour\n",
    "test_feat['day'] = test_feat['datetime'].dt.day\n",
    "test_feat['month'] = test_feat['datetime'].dt.month\n",
    "test_feat['year'] = test_feat['datetime'].dt.year\n",
    "\n",
    "\n",
    "train_feat[\"season\"] = train_feat['season'].astype('category')\n",
    "train_feat[\"weather\"] = train_feat['weather'].astype('category')\n",
    "test_feat[\"season\"] = test_feat['season'].astype('category')\n",
    "test_feat[\"weather\"] = test_feat['weather'].astype('category')\n",
    "\n",
    "\n",
    "train_feat.info() # confirm if casual and registered columns are remmoved - manual drop\n",
    "\n",
    "\n",
    "# setting up individual hyper-parameters for each algorithm\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "gbm_options = {\n",
    "    # 'num_boost_round': 500,\n",
    "    'num_leaves': ag.space.Int(lower=100, upper=500, default=250),\n",
    "    # 'tree_learner': 'feature',  #  serial, feature, data, voting\n",
    "}\n",
    "\n",
    "\n",
    "# https://catboost.ai/docs/concepts/parameter-tuning.html\n",
    "cat_options = {\n",
    "    'iterations':  ag.space.Int(200, 500, default=250),\n",
    "    # 'depth': ag.space.Int(4, 10, default=6),\n",
    "    # 'random_strength': ag.space.Int(0, 20, default=7),\n",
    "}\n",
    "\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "xgb_options = { # empyt dict uses default params\n",
    "}\n",
    "\n",
    "\n",
    "nueral_net_option = {\n",
    "    # 'num_epochs': 250,\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-1, default=5e-4, log=True),\n",
    "    'dropout_prob': ag.space.Real(0.01, 0.6, default=0.1),\n",
    "    # 'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparamter for each model\n",
    "# {} uses autogluon default presets\n",
    "hyperparameters = {\n",
    "    'GBM': gbm_options,\n",
    "    'CAT': cat_options,\n",
    "    'NN_TORCH': nueral_net_option,\n",
    "    'XGB': xgb_options,\n",
    "    'RF': {},\n",
    "    'FASTAI': {}\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': 10,\n",
    "    'searcher': 'auto',  # auto random, bayesopt\n",
    "    'scheduler': 'local', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "predictor_feat = TabularPredictor(label=target, eval_metric=metric).fit(\n",
    "    train_data = train_feat,\n",
    "    time_limit = ttime,\n",
    "    presets = 'best_quality',\n",
    "    hyperparameters = hyperparameters,\n",
    "    hyperparameter_tune_kwargs = hyperparameter_tune_kwargs   \n",
    ")\n",
    "\n",
    "\n",
    "predictor_feat.fit_summary()\n",
    "\n",
    "\n",
    "feat_predictions = predictor_feat.predict(test_feat)\n",
    "feat_predictions.head()\n",
    "\n",
    "\n",
    "feat_predictions[feat_predictions < 0] = 0\n",
    "\n",
    "\n",
    "submission_feat[\"count\"] = feat_predictions\n",
    "submission_feat.to_csv(\"feat_preds/FEAT_submission.csv\", index=False)\n",
    "\n",
    "\n",
    "!kaggle competitions submit -c bike-sharing-demand -f feat_preds/FEAT_submission.csv -m \"New Features submission\"\n",
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6d: AutoGluon low level hyperparameter extreme tuning using new features\n",
    "#### (Tuned Light GBM, CatBoost, Neural Network, Random Forest, XGBoost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_hpo = pd.read_csv('data/train.csv', parse_dates=['datetime'])\n",
    "test_hpo = pd.read_csv('data/test.csv', parse_dates=['datetime'])\n",
    "submission_hpo = pd.read_csv('data/sampleSubmission.csv', parse_dates=['datetime'])\n",
    "\n",
    "ignore_cols = ['casual','registered']\n",
    "train_hpo.drop(ignore_cols, axis=1, inplace=True)  # using the ignored_colums kwargs of TabularPredictor \n",
    "\n",
    "target = 'count'\n",
    "metric = 'root_mean_squared_error'\n",
    "ttime = 10 * 60 # train various models for 10 minutes, 10 x 60 seconds\n",
    "\n",
    "\n",
    "train_hpo['hour'] = train_hpo['datetime'].dt.hour\n",
    "train_hpo['day'] = train_hpo['datetime'].dt.day\n",
    "train_hpo['month'] = train_hpo['datetime'].dt.month\n",
    "train_hpo['year'] = train_hpo['datetime'].dt.year\n",
    "test_hpo['hour'] = test_hpo['datetime'].dt.hour\n",
    "test_hpo['day'] = test_hpo['datetime'].dt.day\n",
    "test_hpo['month'] = test_hpo['datetime'].dt.month\n",
    "test_hpo['year'] = test_hpo['datetime'].dt.year\n",
    "\n",
    "\n",
    "train_hpo[\"season\"] = train_hpo['season'].astype('category')\n",
    "train_hpo[\"weather\"] = train_hpo['weather'].astype('category')\n",
    "test_hpo[\"season\"] = test_hpo['season'].astype('category')\n",
    "test_hpo[\"weather\"] = test_hpo['weather'].astype('category')\n",
    "\n",
    "\n",
    "# train_hpo.info() # confirm if casual and registered columns are remmoved - manual drop\n",
    "\n",
    "\n",
    "# setting up individual hyper-parameters for each algorithm\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "gbm_options = {\n",
    "    'num_boost_round': 500,\n",
    "    'num_leaves': ag.space.Int(lower=100, upper=700), # default=250),\n",
    "    'tree_learner': ['serial', 'feature', 'data', 'voting']\n",
    "}\n",
    "\n",
    "\n",
    "# https://catboost.ai/docs/concepts/parameter-tuning.html\n",
    "cat_options = {\n",
    "    'iterations':  ag.space.Int(50, 1000), #, default=250),\n",
    "    'depth': ag.space.Int(2, 200), #, default=6),\n",
    "    'random_strength': ag.space.Int(0, 200), #, default=7),\n",
    "}\n",
    "\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "xgb_options = { # empyt dict uses default params\n",
    "    'learning_rate': ag.space.Real(1e-3, 1e-1, default=5e-4, log=True),\n",
    "    'max_depth': ag.space.Int(6, 200), #, default=6),\n",
    "    'min_child_weight': ag.space.Int(6, 250), #, default=6),\n",
    "    'subsample': ag.space.Real(0.1, 1, default=0.4),\n",
    "    'lambda':  ag.space.Real(0.5, 10, default=0.4),\n",
    "    'alpha': ag.space.Real(0.5, 10, default=0.4),\n",
    "}\n",
    "\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "rf_options = { # empyt dict uses default params\n",
    "    'n_estimators': ag.space.Int(150, 2000), #, default=6),\n",
    "    'max_depth': ag.space.Int(6, 500), #, default=6),}\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "\n",
    "nueral_net_option = {\n",
    "    'num_epochs': 400,\n",
    "    'learning_rate': ag.space.Real(1e-5, 1e-1, default=5e-4, log=True),\n",
    "    'dropout_prob': ag.space.Real(0.05, 0.6, default=0.1),\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),\n",
    "}\n",
    "\n",
    "\n",
    "# hyperparamter for each model\n",
    "# {} uses autogluon default presets\n",
    "hyperparameters = {\n",
    "    'GBM': gbm_options,\n",
    "    'CAT': cat_options,\n",
    "    'RF': rf_options,\n",
    "    'XGB': xgb_options,\n",
    "    'NN_TORCH': nueral_net_option,\n",
    "    'FASTAI': {},\n",
    "    'KNN': {}\n",
    "}\n",
    "\n",
    "\n",
    "hyperparameter_tune_kwargs = {\n",
    "    'num_trials': 10,\n",
    "    'searcher': 'bayes',  # auto random, 'bayes']\n",
    "    'scheduler': 'local', \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "predictor_hpo = TabularPredictor(label=target, eval_metric=metric).fit(\n",
    "    train_data = train_hpo,\n",
    "    time_limit = ttime,\n",
    "    presets = 'best_quality',\n",
    "    hyperparameters = hyperparameters,\n",
    "    hyperparameter_tune_kwargs = hyperparameter_tune_kwargs   \n",
    ")\n",
    "\n",
    "\n",
    "predictor_hpo.fit_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_hpo = predictor_hpo.predict(test_hpo)\n",
    "predictions_hpo.head()\n",
    "\n",
    "\n",
    "predictions_hpo[predictions_hpo < 0] = 0\n",
    "\n",
    "\n",
    "submission_hpo[\"count\"] = predictions_hpo\n",
    "submission_hpo.to_csv(\"hpo_preds/HPO_submission.csv\", index=False)\n",
    "\n",
    "\n",
    "!kaggle competitions submit -c bike-sharing-demand -f hpo_preds/HPO_submission.csv -m \"New Features - More Tuning Run 2 - submission\"\n",
    "!kaggle competitions submissions -c bike-sharing-demand | tail -n +1 | head -n 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Write a Report\n",
    "### Refer to the markdown file for the full report\n",
    "### Creating plots and table for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Taking the top model score from each training run and creating a line plot to show improvement\n",
    "# You can create these in the notebook and save them to PNG or use some other tool (e.g. google sheets, excel)\n",
    "fig = pd.DataFrame(\n",
    "    {\n",
    "        \"model\": [\"initial\", \"add_features\", 'hpo_init', \"light_hpo\", 'hpo_feat', 'hpo_hpo'],\n",
    "        \"score\": [-51.016775, -30.188990, -114.598932,  -37.163054, -33.831518, -35.414700]\n",
    "    }\n",
    ").plot(x=\"model\", y=\"score\", figsize=(8, 6)).get_figure()\n",
    "fig.savefig('model_train_score.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 3 kaggle scores and creating a line plot to show improvement\n",
    "fig = pd.DataFrame(\n",
    "    {\n",
    "        \"test_eval\": [\"initial\", \"add_features\",  'hpo_init', \"light_hpo\",  'hpo_feat', 'hpo_hpo'],\n",
    "        \"score\":  [1.77321, 0.72416,  1.40947,  0.47104, 0.45144, 0.49312]\n",
    "    }\n",
    ").plot(x=\"test_eval\", y=\"score\", figsize=(8, 6)).get_figure()\n",
    "fig.savefig('model_test_score.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 3 hyperparameters we tuned with the kaggle score as the result\n",
    "pd.DataFrame({\n",
    "    \"model\": [\"initial\",    \"add_features\",     \"hpo\"],\n",
    "    \"hpo1\": ['num_leaves',  'num_leaves',   ['num_leaves', 'num_boost_round', 'tree_learner']],\n",
    "    \"hpo2\": ['iterations',  'iterations',   ['iterations', 'depth', 'num_epochs']],\n",
    "    \"hpo3\": ['learning_rate',   'learning_rate',    ['learning_rate', 'dropout_prob', 'random_strength']],\n",
    "    \"score\": [1.4094, 0.45144, 0.49312]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d3615d37ed2d614cdbd080d2a5821c07ab811150185428c82234695fac5de6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
